{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6efaaa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "import scipy.cluster.hierarchy as shc\n",
    "from scipy.cluster.hierarchy import linkage, fclusterdata\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.cluster import KMeans, DBSCAN, AgglomerativeClustering\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import silhouette_score, calinski_harabasz_score\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44fb123",
   "metadata": {},
   "source": [
    "# Read the data with SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fea64b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "# Specifying the path to the database file\n",
    "db_file_path = \"/dbfs/FileStore/tables/digisusti/2024-footprint/olist.db\"\n",
    "\n",
    "# Checking if the file 'olist.db' exists in the specified path\n",
    "df_customers = spark.read.format(\"jdbc\").option(\"url\", f\"jdbc:sqlite:{db_file_path}\").option(\"dbtable\", \"customers\").option(\"fetchsize\", \"1000\").load()\n",
    "df_orders = spark.read.format(\"jdbc\").option(\"url\", f\"jdbc:sqlite:{db_file_path}\").option(\"dbtable\", \"orders\").option(\"fetchsize\", \"1000\").load()\n",
    "df_order_reviews = spark.read.format(\"jdbc\").option(\"url\", f\"jdbc:sqlite:{db_file_path}\").option(\"dbtable\", \"order_reviews\").option(\"fetchsize\", \"1000\").load()\n",
    "df_order_items = spark.read.format(\"jdbc\").option(\"url\", f\"jdbc:sqlite:{db_file_path}\").option(\"dbtable\", \"order_items\").option(\"fetchsize\", \"1000\").load()\n",
    "df_order_pymts = spark.read.format(\"jdbc\").option(\"url\", f\"jdbc:sqlite:{db_file_path}\").option(\"dbtable\", \"order_pymts\").option(\"fetchsize\", \"1000\").load()\n",
    "\n",
    "# Registering the DataFrames as temporary views\n",
    "df_customers.createOrReplaceTempView(\"customers_view\")\n",
    "df_orders.createOrReplaceTempView(\"orders_view\")\n",
    "df_order_reviews.createOrReplaceTempView(\"order_reviews_view\")\n",
    "df_order_items.createOrReplaceTempView(\"order_items_view\")\n",
    "df_order_pymts.createOrReplaceTempView(\"order_pymts_view\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32459d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = spark.sql(\"\"\"\n",
    "SELECT\n",
    "    c.customer_unique_id,\n",
    "    (datediff(date('2018-10-17'), MIN(o.order_purchase_timestamp)) + 1) AS seniority,\n",
    "    COUNT(or_reviews.order_id) AS nb_reviews,\n",
    "    AVG(or_reviews.review_score) AS average_review_score,\n",
    "    COUNT(o.order_id) AS nb_orders,\n",
    "    AVG(oi.price) AS average_basket,\n",
    "    SUM(CASE WHEN o.order_status = 'canceled' THEN 1 ELSE 0 END) AS nb_canceled\n",
    "FROM\n",
    "    customers_view c\n",
    "JOIN\n",
    "    orders_view o ON c.customer_id = o.customer_id\n",
    "LEFT JOIN\n",
    "    order_reviews_view or_reviews ON o.order_id = or_reviews.order_id\n",
    "JOIN\n",
    "    order_items_view oi ON o.order_id = oi.order_id\n",
    "GROUP BY\n",
    "    c.customer_unique_id\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d2ff4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying the result\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732115a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df = result.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9017774b",
   "metadata": {},
   "source": [
    "# Transform and select features\n",
    "......."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89cf27e",
   "metadata": {},
   "source": [
    "# Build model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d3e9341",
   "metadata": {},
   "source": [
    "## Agglomerative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3d94cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory_used = df.memory_usage().sum()\n",
    "print(memory_used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611e226f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of AgglomerativeClustering with 3 clusters\n",
    "clustering = AgglomerativeClustering(n_clusters=3, affinity='euclidean', linkage='ward')\n",
    "\n",
    "df = df.sample(frac=0.4)\n",
    "\n",
    "# Fit the clustering model using numeric features (excluding object type features)\n",
    "clustering.fit(df.select_dtypes(exclude='object'))\n",
    "\n",
    "# Assign the cluster labels to a new column 'cluster' in the DataFrame\n",
    "df['cluster'] = clustering.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac415462",
   "metadata": {},
   "source": [
    "## DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ad1319",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbscan = DBSCAN(eps=0.5, min_samples=5)  # Vous pouvez ajuster eps et min_samples en fonction de vos données\n",
    "dbscan.fit(df.select_dtypes(exclude='object'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523b4318",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer une instance de UMAP\n",
    "umap_model = umap.UMAP(n_neighbors=10, min_dist=0.1, metric='euclidean')\n",
    "\n",
    "# Réduire les dimensions\n",
    "data_2d = umap_model.fit_transform(df.select_dtypes(exclude='object'))\n",
    "\n",
    "# Visualiser les données réduites\n",
    "plt.scatter(data_2d[:, 0], data_2d[:, 1], c=dbscan.labels_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9273216f",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "........."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
